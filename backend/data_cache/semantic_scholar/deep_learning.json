[
  {
    "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
    "authors": [
      "Adam Paszke",
      "Sam Gross",
      "Soumith Chintala"
    ],
    "venue": "Neural Information Processing Systems",
    "pub_date": "3 December 2019",
    "tldr": "TLDR\nThis paper details the principles that drove the implementation of PyTorch and how they are reflected in its architecture, and explains how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance.\nExpand",
    "pdf_link": "https://arxiv.org/pdf/1912.01703.pdf"
  },
  {
    "title": "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation",
    "authors": [
      "Fabian Isensee",
      "P. Jaeger",
      "Simon A. A. Kohl",
      "Jens Petersen",
      "Klaus Hermann Maier-Hein"
    ],
    "venue": "Nature Methods",
    "pub_date": "7 December 2020",
    "tldr": "N/A",
    "pdf_link": "N/A"
  },
  {
    "title": "Towards Deep Learning Models Resistant to Adversarial Attacks",
    "authors": [
      "A. Ma̧dry",
      "Aleksandar Makelov",
      "Ludwig Schmidt",
      "Dimitris Tsipras",
      "Adrian Vladu"
    ],
    "venue": "International Conference on Learning…",
    "pub_date": "19 June 2017",
    "tldr": "TLDR\nThis work studies the adversarial robustness of neural networks through the lens of robust optimization, and suggests the notion of security against a first-order adversary as a natural and broad security guarantee.\nExpand",
    "pdf_link": "https://arxiv.org/pdf/1706.06083.pdf"
  },
  {
    "title": "Review of deep learning: concepts, CNN architectures, challenges, applications, future directions",
    "authors": [
      "Laith Alzubaidi",
      "Jinglan Zhang",
      "Laith Farhan"
    ],
    "venue": "Journal of Big Data",
    "pub_date": "31 March 2021",
    "tldr": "TLDR\nThis review attempts to provide a more comprehensive survey of the most important aspects of DL and including those enhancements recently added to the field, and outlines the importance of DL, and presents the types of DL techniques and networks.\nExpand",
    "pdf_link": "N/A"
  },
  {
    "title": "What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?",
    "authors": [
      "Alex Kendall",
      "Y. Gal"
    ],
    "venue": "Neural Information Processing Systems",
    "pub_date": "15 March 2017",
    "tldr": "TLDR\nA Bayesian deep learning framework combining input-dependent aleatoric uncertainty together with epistemic uncertainty is presented, which makes the loss more robust to noisy data, also giving new state-of-the-art results on segmentation and depth regression benchmarks.\nExpand",
    "pdf_link": "https://arxiv.org/pdf/1703.04977.pdf"
  },
  {
    "title": "A survey on Image Data Augmentation for Deep Learning",
    "authors": [
      "Connor Shorten",
      "T. Khoshgoftaar"
    ],
    "venue": "Journal of Big Data",
    "pub_date": "6 July 2019",
    "tldr": "TLDR\nThis survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing DataAugmentation, a data-space solution to the problem of limited data.\nExpand",
    "pdf_link": "N/A"
  },
  {
    "title": "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations",
    "authors": [
      "M. Raissi",
      "P. Perdikaris",
      "G. Karniadakis"
    ],
    "venue": "Journal of Computational Physics",
    "pub_date": "1 February 2019",
    "tldr": "N/A",
    "pdf_link": "N/A"
  },
  {
    "title": "Deep Learning with Differential Privacy",
    "authors": [
      "Martín Abadi",
      "Andy Chu",
      "Li Zhang"
    ],
    "venue": "Conference on Computer and Communications…",
    "pub_date": "1 July 2016",
    "tldr": "TLDR\nThis work develops new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy, and demonstrates that deep neural networks can be trained with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.\nExpand",
    "pdf_link": "N/A"
  },
  {
    "title": "Object Detection With Deep Learning: A Review",
    "authors": [
      "Zhong-Qiu Zhao",
      "Peng Zheng",
      "Shou-tao Xu",
      "Xindong Wu"
    ],
    "venue": "IEEE Transactions on Neural Networks and Learning…",
    "pub_date": "15 July 2018",
    "tldr": "TLDR\nThis paper provides a review of deep learning-based object detection frameworks and focuses on typical generic object detection architectures along with some modifications and useful tricks to improve detection performance further.\nExpand",
    "pdf_link": "N/A"
  },
  {
    "title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning",
    "authors": [
      "Y. Gal",
      "Zoubin Ghahramani"
    ],
    "venue": "International Conference on Machine Learning",
    "pub_date": "6 June 2015",
    "tldr": "TLDR\nA new theoretical framework is developed casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes, which mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy.\nExpand",
    "pdf_link": "https://arxiv.org/pdf/1506.02142.pdf"
  }
]